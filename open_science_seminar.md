---
# YAML metadata
title: Reproducibility is process
author: Matthew Brett
bibliography: data.bib
<#ifndef HANDOUT>
suppress-bibliography: true
<#endif>
---

# Computational reproducibility

An analysis is computationally reproducible} when someone other than the
original author of an analysis can produce on their own computer the
reported results using the authors' data, code, and instructions
[@buckheit1995wavelab].

# Why computational reproducibility?

> The scientific method's central motivation is the ubiquity of error
> - the awareness that mistakes and self-delusion can creep in
> absolutely anywhere and that the scientist's effort is primarily
> expended in recognizing and rooting out error.

[@donoho2009reproducible]

# Why computational reproducibility?

> Computing results are now being presented in a very loose, “breezy”
> way—in journal articles, in conferences, and in books. All too often
> one simply takes computations at face value. This is spectacularly
> against the evidence of my own experience. I would much rather that at
> talks and in referee reports, the possibility of such error were
> seriously examined.

[@donoho2010invitation]

# Otherwise

> An article about computational science in a scientific publication is
> *not* the scholarship itself, it is merely **advertising** of the
> scholarship. The actual scholarship is the complete software
> development environment and the complete set of instructions which
> generated the figures.

[@buckheit1995wavelab].

# Towards reproducibility

* structured, commented code
* code review
* tests
* version control
* records of discussion and decisions
* all analysis by code.

Put otherwise, [You can't do data science in
a GUI](https://www.youtube.com/watch?v=cpbtcsGE0OA)

# This is too much, what about baby steps?

With a joke.

# This is too much, reprise

[Reproducible and Collaborative Statistical Data
Science](http://www.jarrodmillman.com/rcsds).

* Autumn 2015, UC Berkeley.
* ~40 students
* undergraduates, some graduates, mainly statistics
* neuroimaging as example scientific problem
* large open-ended project
* projects had to be fully reproducible.

[@millman2018rcsds],
<https://www.frontiersin.org/articles/10.3389/fnins.2018.00727/full>

# The projects

* <https://github.com/berkeley-stat159>
* [A simple project](https://github.com/berkeley-stat159/project-epsilon)
* [An heroic project](https://github.com/berkeley-stat159/project-lambda)

# Why?

* massive increase in efficiency, reduction in error

# Why not?

* [I don't make many errors](https://dzone.com/articles/reality-developers-life-gifs)
* The errors I make aren't very important

# How shall this be done?

* Factors in Berkeley.
* What we need here.

# Is this the end?

Yes, it's the end of the talk.

All material for these slides at
<https://github.com/matthew-brett/open-science-seminar>

Handout at
<https://github.com/matthew-brett/open-science-seminar/blob/master/open_science_seminar_handout.pdf>

<#ifdef HANDOUT>
# References
<#endif>
